---
title: "clean_data"
author: "Austin Kennedy"
date: "1/12/2022"
output: html_document
---

```{r Clear memory and setup}
rm(list=ls())
options(scipen=999)
```

```{r Load Packages}
library(tidyverse)
```

```{r Load Data}
# odi1 <- read.csv("../Input/ODI/ODI_1996-2001.csv")
# odi2 <- read.csv("../Input/ODI/ODI_2002-2011.csv")
odi <- read.csv("../Input/ODI/ODI_2002-2011.csv")
fdi <- read.csv("../Input/fdi/fdi_country_industry.csv", nrows = 67, na.strings = "n.s.", check.names = FALSE)
#fdi <- read.csv("../Input/us_inward_country.csv", nrows = 65, na.strings = "n.s.", check.names = FALSE)
```

# ```{r Change variable names to match}
# odi1 <- odi1 %>% rename(EMP_Q1 = Q1,
#                         HOURS_Q2 = Q2,
#                         UNUSUAL_Q3 = Q3A,
#                         STRIKE_Q3 = Q3B,
#                         SHUT_Q3 = Q3C,
#                         SEASONAL_Q3 = Q3D,
#                         DISASTER_Q3 = Q3E,
#                         SHORT_Q3 = Q3F,
#                         LONG_Q3 = Q3G,
#                         OREASON_Q3 = Q3H,
#                         )
# ```
```{r ODI data}
#Create two and three digit naics for each firm
odi <- odi %>%
  mutate(naics_2 = as.numeric(substr(NAICS, 1, 2)),
         naics_3 = as.numeric(substr(NAICS, 1, 3)),
         naics_4 = as.numeric(substr(NAICS, 1, 4)),
         naics_5 = as.numeric(substr(NAICS, 1, 5)),
         .before = "EMP_Q1")

odi <- odi %>%
  drop_na(NAICS)

#Generate TCRs
odi <- odi %>%
  mutate(tcr = (INJ_M1*200000) / HOURS_Q2, .before = "EMP_Q1")

```

```{r Clean FDI data}
# fdi <- fdi[,-2] #Second column is the same as the first, but with spacing
colnames(fdi)[1] = "Country"
fdi <- fdi[rowSums(is.na(fdi)) != (ncol(fdi)-1),] #take out rows that have all NAs
fdi$Country <- trimws(fdi$Country) #Remove whitespace
fdi <- fdi[!(fdi$Country %in% c("Addenda:", "Other")),]  #Remove rows that aren't useful
fdi[fdi == "(D)"] <- NA #(D) represents confidential values in the source data
fdi[fdi == "(*)"] <- 0 #(*) represents close to zero in the source data

years <- as.numeric(fdi[2,])
industries <- colnames(fdi)

#Function to insert row
insertRow <- function(existingDF, newrow, r) {
  existingDF[seq(r+1,nrow(existingDF)+1),] <- existingDF[seq(r,nrow(existingDF)),]
  existingDF[r,] <- newrow
  existingDF
}

fdi <- insertRow(fdi, industries, 1) #Insert colnames as a row to not be lost
colnames(fdi) <- years #Change col names to years for wide to long transition

fdi <- t(fdi) #transpose
#Change col names to countries
countries <- fdi[1,] 
colnames(fdi) <- countries
fdi <- fdi[-1,]

colnames(fdi)[1:3] = c("title_2", "title_3", "Year")
rownames(fdi) <- NULL
fdi <- as_tibble(fdi)
# fdi <- fdi %>% pivot_longer(-c("title_2", "title_3", "Year"), names_to = "Country", values_to = "fdi") #Wide to long
```

```{r Match NAICS codes to fdi industries}
naics <- read.csv("../Input/naics07.csv")
naics <- naics[-1,-1]
colnames(naics) <- c("code", "title_3")
naics <- as_tibble(naics)
naics <- subset(naics, nchar(naics$code) <= 5)
# new <- merge(fdi, naics, by = "title_3")

library(fuzzyjoin)

new <- stringdist_join(fdi, naics,
                by = "title_3",
                mode = "left",
                ignore_case = TRUE,
                method = "jw",
                max_dist = 99,
                distance_col = "dist") %>%
  group_by(title_3.x) %>%
  slice_min(order_by = dist, n = 1)

new <- new[, c("title_2", "title_3.x", "code", "title_3.y", "dist")]
uni <- distinct(new, title_3.x, title_3.y, .keep_all = TRUE)
#Manually recode unmatched industries, probably not best practice but best I can do
uni <- uni %>% mutate(industry = case_when(title_3.x == "All Industries Total" ~ "All Industries Total",
                                           title_3.x == "Depository Institutions" ~ "Credit Intermediation and Related Activities",
                                           title_3.x == "Finance (except depository institutions) and insurance" ~ "Finance and Insurance",
                                           title_3.x == "Other Industries" ~ "Other Industries",
                                           title_3.x == "Other Manufacturing" ~ "Manufacturing",
                                           title_3.x == "Total Manufacturing" ~ "Manufacturing",
                                           TRUE ~ title_3.y))
uni <- merge(uni, naics, by.x = "industry", by.y = "title_3")
fdi <- merge(fdi, uni[, c("code.y","title_3.x")], by.x = "title_3", by.y = "title_3.x", all.x = TRUE)
fdi <- rename(fdi, code = code.y)
# fdi <- fdi[, c("title_2", "title_3", "code", "Year", "Country", "fdi")]
fdi <- fdi %>% select("title_2", "title_3", "code", everything())

#Make country-level fdi data as long as possible
fdi <- fdi %>% pivot_longer(-c("title_2", "title_3","code", "Year"), names_to = "Country", values_to = "fdi") #Wide to long
write.csv(fdi, "../Temporary/fdi_country_year.csv")
```

```{r Import industry-only fdi data}
fdi_ind <- read.csv("../Input/fdi/fdi_total_industry.csv", na.strings = "n.s.", check.names = FALSE)
```

```{r Clean industry fdi data}
# fdi <- fdi[,-2] #Second column is the same as the first, but with spacing
colnames(fdi_ind)[1] <- "industry"
fdi_ind <- fdi_ind[rowSums(is.na(fdi_ind)) != (ncol(fdi_ind)-1),] #take out rows that have all NAs
fdi_ind$industry <- trimws(fdi_ind$industry) #Remove whitespace
fdi_ind <- fdi_ind[!(fdi_ind$industry %in% c("Addendum:", "Other")),]  #Remove rows that aren't useful
fdi_ind[fdi_ind == "(D)"] <- NA #(D) represents confidential values in the source data
fdi_ind[fdi_ind == "(*)"] <- 0 #(*) represents close to zero in the source data

fdi_ind <- fdi_ind %>% pivot_longer(!industry, names_to = "year", values_to = "fdi")
naics <- rename(naics, industry = title_3)
#Match industries to NAICS codes
match <- stringdist_join(fdi_ind, naics, #fuzzy matching
                    by = "industry",
                    mode = "left",
                    ignore_case = TRUE,
                    method = "jw",
                    max_dist = 99,
                    distance_col = "dist") %>%
  group_by(industry.x) %>%
  slice_min(order_by = dist, n = 1)

match <- distinct(match, industry.x, industry.y, .keep_all = TRUE)
match <- match %>% filter(dist < 0.25)

fdi_ind_matched <- merge(fdi_ind, match[, c("code", "industry.x", "industry.y")], by.x = "industry", by.y = "industry.x")

#Uncomment to check how well matching did
  
# unmatched <- match %>% filter(dist > 0.05) %>% select(industry.x, industry.y, dist)
# unmatched <- distinct(unmatched, industry.x, industry.y, .keep_all = TRUE)
# unmatched <- unmatched %>% filter(dist < 0.25) %>% select(industry.x, industry.y, dist)

fdi_ind_matched$code <- as.numeric(fdi_ind_matched$code)
fdi_ind_matched$year <- as.numeric(fdi_ind_matched$year)

```

```{r Merge odi and fdi data}
m_5 <- merge(odi, fdi_ind_matched, by.x = c("Year","naics_5"), by.y = c("year","code"))
a_5 <- anti_join(odi, fdi_ind_matched, by = c("naics_5" = "code" , "Year" = "year"))#find rows that weren't matched

m_4 <- merge(a_5, fdi_ind_matched, by.x = c("Year","naics_4"), by.y = c("year","code")) #merge only unmatched
a_4 <- anti_join(a_5, fdi_ind_matched, by = c("naics_4" = "code" , "Year" = "year"))#find rows that weren't matched
m_3 <- merge(a_4, fdi_ind_matched, by.x = c("Year", "naics_3"), by.y = c("year", "code"))
a_3 <- anti_join(a_4, fdi_ind_matched, by = c("naics_3" = "code" , "Year" = "year"))

m_2 <- merge(a_3, fdi_ind_matched, by.x = c("Year", "naics_2"), by.y = c("year", "code"))

odi_matched <- rbind(m_5,m_4,m_3,m_2)
odi_matched <- odi_matched[order(odi_matched$Year),]

odi_matched <- odi_matched %>% mutate(tcr = (INJ_M1*200000) / HOURS_Q2,
                              .before = "EMP_Q1")

odi_matched$fdi <- as.numeric(odi_matched$fdi)
```

```{r Export matched odi data}
#write.csv(odi_matched, "../Temporary/odi_fdi.csv", row.names = FALSE)
```

```{r Import country safety data}
country_safety <- read.csv("../Temporary/country_safety.csv")
```

```{r Source country injury rate}
#Make country-level fdi data as long as possible
# fdi <- fdi %>% pivot_longer(-c("title_2", "title_3","code", "Year"), names_to = "Country", values_to = "fdi") #Wide to long
#Convert country safety to per 100 instead of 100,000 for comparisons
country_safety$rate <- country_safety$rate / 1000

fdi_safety <- merge(fdi, country_safety[,c("rate","Country", "Year")], by = c("Country", "Year"))

#For now, just work with firms that can be matched at the 3-digit level
merge_1 <- merge(odi, fdi_safety, by.x = c("Year","naics_3"), by.y = c("Year","code"))

#Create new var with avg worker injuries by industry and year
merge_1 <- merge_1 %>%
  group_by(naics_3, Year) %>%
  mutate(inj_ind = mean(tcr))

#Create new var with US safety rate by year

us_safety <- country_safety %>%
  filter(Country == "United States")

merge_1 <- merge(merge_1, us_safety[, c("rate", "Year")], by = "Year")

merge_1 <- rename(merge_1, inj_us = rate.y)
merge_1 <- rename(merge_1, inj_foreign = rate.x)
merge_1$fdi <- as.numeric(merge_1$fdi)

#Export data with source country fdi
# write.csv(merge_1, "../Temporary/odi_fdi_source.csv", row.names = FALSE)

```

```{r Interaction summation and FDI-weighted injury rate}
odi_plant <- merge_1

#remove NAs and negative fdi

odi_plant <- odi_plant[!is.na(odi_plant$fdi),]
odi_plant <- odi_plant[!(odi_plant$fdi<0),]

#Summed Interaction
interact <- odi_plant %>%
  mutate(interact = inj_foreign*fdi) %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  summarize(int_sum = sum(interact, na.rm = TRUE),
            fdi_tot = sum(fdi, na.rm = TRUE))

#FDI-weighted avg
wavg <- odi_plant %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  mutate(fdi_share = fdi/sum(fdi, na.rm = TRUE)) %>%
  mutate(inj_weighted = fdi_share*inj_foreign) %>%
  summarize(weight_avg = sum(inj_weighted))

#Yearly world average injury rate
inj_world <- country_safety %>%
  group_by(Year) %>%
  summarize(inj_world = mean(rate))

odi_plant <- merge(odi_plant, inj_world, by = "Year")

#FDI-weighted deviations from world average, summed
dev <- odi_plant %>%
  mutate(dev = inj_foreign - inj_world) %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  mutate(fdi_share = fdi/sum(fdi, na.rm = TRUE)) %>%
  summarize(davg = sum(fdi_share*dev))
  


odi_plant <- merge(odi, interact, by = c("STREET", "Year", "ESTAB_NAME"))
odi_plant <- merge(odi_plant, wavg, by = c("STREET", "Year", "ESTAB_NAME"))
odi_plant <- merge(odi_plant, dev, by = c("STREET", "Year", "ESTAB_NAME"))


  
#Export plant-level data
write.csv(odi_plant, "../Temporary/odi_plant.csv")

```

```{r Create Interaction Summation}
odi_plant <- merge_1

#Sum of the interaction of FDI and source injury rate 
odi_plant <- odi_plant %>%
  mutate(interact = inj_foreign*fdi) %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  summarize(int_sum = sum(interact, na.rm = TRUE),
            fdi_tot = sum(fdi, na.rm = TRUE))

odi_plant <- merge(odi, odi_plant, by = c("STREET", "Year", "ESTAB_NAME"))


# write.csv(odi_plant, "../Temporary/odi_plant.csv", row.names = FALSE)

```


```{r FDI weighted injuries}

  
```

```{r Find Safe and Unsafe}

#Find safe and unsafe fdi
merge_2 <- merge_1 %>% 
  group_by(STREET, Year) %>%
  summarize(fdi_safe_us = sum(fdi[which(inj_foreign <= inj_us)], na.rm = TRUE),
            fdi_unsafe_us = sum(fdi[which(inj_foreign > inj_us)], na.rm = TRUE),
            fdi_safe_ind = sum(fdi[which(inj_foreign <= inj_ind)], na.rm = TRUE),
            fdi_unsafe_ind = sum(fdi[which(inj_foreign > inj_ind)], na.rm = TRUE),
            fdi_safe_plant = sum(fdi[which(inj_foreign <= tcr)], na.rm = TRUE),
            fdi_unsafe_plant = sum(fdi[which(inj_foreign > tcr)], na.rm = TRUE)
            )

#merge odi and safe/unsafe
odi_final <- merge(odi, merge_2, by = c("STREET", "Year"))
```

```{r Export ODI final}
write.csv(odi_final, "../Temporary/odi_fdi_safety.csv", row.names = FALSE)
```


```{r Fuzzy matching if data is long}
# naics <- read.csv("../Input/naics07.csv")
# naics <- naics[-1,-1]
# colnames(naics) <- c("code", "title_3")
# naics <- as_tibble(naics)
# naics <- subset(naics, nchar(naics$code) <= 5)
# # new <- merge(fdi, naics, by = "title_3")
# library(fuzzyjoin)
# new <- stringdist_join(fdi, naics,
#                 by = "title_3",
#                 mode = "left",
#                 ignore_case = TRUE,
#                 method = "jw",
#                 max_dist = 99,
#                 distance_col = "dist") %>%
#   group_by(title_3.x) %>%
#   slice_min(order_by = dist, n = 1)
# uni <- distinct(new, title_3.x, title_3.y, .keep_all = TRUE)
# #Manually recode unmatched industries, probably not best practice but best I can do
# uni <- uni %>% mutate(industry = case_when(title_3.x == "All Industries Total" ~ "All Industries Total",
#                                            title_3.x == "Depository Institutions" ~ "Credit Intermediation and Related Activities",
#                                            title_3.x == "Finance (except depository institutions) and insurance" ~ "Finance and Insurance",
#                                            title_3.x == "Other Industries" ~ "Other Industries",
#                                            title_3.x == "Other Manufacturing" ~ "Manufacturing",
#                                            title_3.x == "Total Manufacturing" ~ "Manufacturing",
#                                            TRUE ~ title_3.y))
# uni <- merge(uni, naics, by.x = "industry", by.y = "title_3")
# fdi <- merge(fdi, uni[, c("code.y","title_3.x")], by.x = "title_3", by.y = "title_3.x", all.x = TRUE)
# fdi <- rename(fdi, code = code.y)
# fdi <- fdi[, c("title_2", "title_3", "code", "Year", "Country", "fdi")]
```





```{r Create Plant IDs}
#Using street addresses because want to identify individual plants instead of firms
odi <- odi %>%
  group_by(STREET) %>%
  mutate(ID = cur_group_id())

#check no. of unique IDs
length(unique(odi[["ID"]]))
```

```{r Test code}
uni <- distinct(new, title_3.x, title_3.y)
```


















